# L2 Agent Backend Configuration

# Server Configuration
PORT=3000

# CORS Configuration
# Comma-separated list of allowed origins (chrome-extension:// will be added automatically)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# LLM Provider Configuration
# Your private internal LLM API endpoint
LLM_API_URL=http://localhost:8000/api/chat
# API key for your LLM provider (if required)
LLM_API_KEY=your-api-key-here
# Model name (optional, defaults to 'default')
LLM_MODEL=gpt-4

# LLM Default Parameters (optional)
# These will be merged with each request
# LLM_MAX_TOKENS=2000
# LLM_TEMPERATURE=0.7
